{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDHHyJsZdFFp"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THTB3L8TxZ1Q"
      },
      "source": [
        "# Getting Started With MCP Toolbox\n",
        "\n",
        "This guide demonstrates how to quickly run\n",
        "[Toolbox](https://github.com/googleapis/genai-toolbox) end-to-end in Google\n",
        "Colab using Python, BigQuery, and either [Google\n",
        "GenAI](https://pypi.org/project/google-genai/), [ADK](https://google.github.io/adk-docs/),\n",
        "[Langgraph](https://www.langchain.com/langgraph)\n",
        "or [LlamaIndex](https://www.llamaindex.ai/).\n",
        "\n",
        "Within this Colab environment, you'll\n",
        "- Set up a `BigQuery Dataset`.\n",
        "- Launch a Toolbox server.\n",
        "- Connect to Toolbox and develop a sample `Hotel Booking` application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLQzss0WxeI1"
      },
      "source": [
        "## Step 1: Set up your dataset\n",
        "\n",
        "In this section, we will\n",
        "1. Create a dataset in your bigquery project.\n",
        "1. Insert example data into the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zTtKdvbwAag3",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @markdown Please fill in the value below and then run the cell.\n",
        "BIGQUERY_PROJECT = \"genaipla-aiplayground2-sa-bf14\" # @param {type:\"string\"}\n",
        "DATASET = \"fullfil\" # @param {type:\"string\"}\n",
        "TABLE_ID = \"order_line_life_cycle\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDaRyfx3PhXM"
      },
      "source": [
        "> You need to authenticate as an IAM user so this notebook can access your Google Cloud Project. This access is necessary to use Google's LLM models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c1_GR5NwPhXM"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "\n",
        "# Authenticate the user for Google Cloud access\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2eNdr9LYyhuV"
      },
      "outputs": [],
      "source": [
        "# Create the dataset if it does not exist\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import exceptions\n",
        "\n",
        "bqclient = bigquery.Client(project=BIGQUERY_PROJECT)\n",
        "dataset_ref = bqclient.dataset(DATASET)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPuheP8DIt3p"
      },
      "source": [
        "## Step 2: Install and configure Toolbox\n",
        "\n",
        "In this section, we will\n",
        "1. Download the latest version of the toolbox binary.\n",
        "2. Create a toolbox config file.\n",
        "3. Start a toolbox server using the config file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl1IeaqZbMYh"
      },
      "source": [
        "Download the [latest](https://github.com/googleapis/genai-toolbox/releases) version of Toolbox as a binary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbsQ1Aa-IszB",
        "outputId": "0614ed26-fc50-4c96-8ab4-43f623072a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  133M  100  133M    0     0   103M      0  0:00:01  0:00:01 --:--:--  103M\n"
          ]
        }
      ],
      "source": [
        "version = \"0.16.0\" # x-release-please-version\n",
        "! curl -O https://storage.googleapis.com/genai-toolbox/v{version}/linux/amd64/toolbox\n",
        "\n",
        "# Make the binary executable\n",
        "! chmod +x toolbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ovlzi2RVJGM5"
      },
      "outputs": [],
      "source": [
        "TOOLBOX_BINARY_PATH = \"/content/toolbox\"\n",
        "SERVER_PORT = 5000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNg7v_FeTYJu"
      },
      "source": [
        "Create a tools file with the following functions:\n",
        "\n",
        "- `Database Connection (sources)`: `Includes details for connecting to our hotels database.`\n",
        "- `Tool Definitions (tools)`: `Defines five tools for database interaction:`\n",
        "  - `search-hotels-by-name`\n",
        "  - `search-hotels-by-location`\n",
        "  - `book-hotel`\n",
        "  - `update-hotel`\n",
        "  - `cancel-hotel`\n",
        "\n",
        "Our application will leverage these tools to interact with the hotels table.\n",
        "\n",
        "For detailed configuration options, please refer to the [Toolbox documentation](https://googleapis.github.io/genai-toolbox/getting-started/configure/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Jje8N5fScchw"
      },
      "outputs": [],
      "source": [
        "# Create a tools file at runtime.\n",
        "# You can also upload a tools file and use that to run toolbox.\n",
        "tools_file_name = \"tools.yml\"\n",
        "file_content = f\"\"\"\n",
        "sources:\n",
        "  my-bigquery-source:\n",
        "    kind: bigquery\n",
        "    project: genaipla-aiplayground2-sa-bf14\n",
        "    location: us\n",
        "tools:\n",
        "  search-order:\n",
        "    kind: bigquery-sql\n",
        "    source: my-bigquery-source\n",
        "    description: Use this tool to get all details for a specific order by using its order number.\n",
        "    parameters:\n",
        "      - name: order_number\n",
        "        type: string\n",
        "        description: The unique number for the order you need to find.\n",
        "    statement: SELECT * FROM `fullfil.order_line_life_cycle` WHERE order_number = CAST(@order_number AS INT64);\n",
        "toolsets:\n",
        "  my-bigquery-toolset:\n",
        "    - search-order\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JPNXr4y58tMH"
      },
      "outputs": [],
      "source": [
        "with open(tools_file_name, 'w', encoding='utf-8') as f:\n",
        "    f.write(file_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5ZH5VuYzdP_W"
      },
      "outputs": [],
      "source": [
        "TOOLS_FILE_PATH = f\"/content/{tools_file_name}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iZGQzYUF-pho"
      },
      "outputs": [],
      "source": [
        "# Start a toolbox server\n",
        "! nohup {TOOLBOX_BINARY_PATH} --tools-file {TOOLS_FILE_PATH} -p {SERVER_PORT} > toolbox.log 2>&1 &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PJpKOBieKOV",
        "outputId": "51ff59f3-10a8-48c5-d152-a6faad3be78e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "toolbox 1341 root    3u  IPv4  54172      0t0  TCP localhost:5000 (LISTEN)\n"
          ]
        }
      ],
      "source": [
        "# Check if toolbox is running\n",
        "!sudo lsof -i :{SERVER_PORT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yFH4JK7JEAv"
      },
      "source": [
        "## Step 3: Connect your agent to Toolbox\n",
        "\n",
        "In this section, you will\n",
        "1. Establish a connection to the tools by creating a Toolbox client.\n",
        "2. Build an agent that leverages the tools and an LLM for Hotel Booking functionality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0Jc-0YNdhQd",
        "outputId": "cf708dcc-0926-4f98-c478-1f37d85ead2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "# Configure gcloud.\n",
        "!gcloud config set project {BIGQUERY_PROJECT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J46eLkFbNhWq"
      },
      "source": [
        "> You can use ADK, LangGraph, or LlamaIndex to develop a Toolbox based application. Run one of the [Connect Using LangGraph](#scrollTo=pbapNMhhL33S), [Connect using LlamaIndex](#scrollTo=04iysrm_L_7v&line=1&uniqifier=1) or [Connect using ADK](#scrollTo=yA3rAiELIds5) sections below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbapNMhhL33S"
      },
      "source": [
        "### Connect Using LangGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uraBx8mbMXnV",
        "outputId": "19a7598d-1ce1-40cb-f376-c96c363a017b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install the Toolbox Langchain package\n",
        "!pip install toolbox-langchain --quiet\n",
        "!pip install langgraph --quiet\n",
        "\n",
        "# Install the Langchain llm package\n",
        "# TODO(developer): replace this with another model if needed\n",
        "! pip install langchain-google-vertexai --quiet\n",
        "# ! pip install langchain-google-genai\n",
        "# ! pip install langchain-anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oHNnZnBM8FU"
      },
      "source": [
        "Create a LangGraph Order Agent which can Search, Book and Cancel hotels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "Br3ucM46M9uc",
        "outputId": "ff49d6a3-2bac-4a37-c057-e0fc1c724de6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'inputs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2672251023.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#inputs = {\"messages\": [(\"user\", prompt + query)]}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
          ]
        }
      ],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "# TODO(developer): replace this with another import if needed\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# from langchain_anthropic import ChatAnthropic\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "from toolbox_langchain import ToolboxClient\n",
        "\n",
        "prompt = \"\"\"\n",
        " You are Order Management Expert You are good at query on Order_number and extract data from the table.\n",
        "\"\"\"\n",
        "\n",
        "queries = [\n",
        "    \"find the order_number details for order_number 1042567961\"\n",
        "]\n",
        "\n",
        "# Create an LLM to bind with the agent.\n",
        "# TODO(developer): replace this with another model if needed\n",
        "model = ChatVertexAI(model_name=\"gemini-2.0-flash-001\", project=BIGQUERY_PROJECT)\n",
        "# model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\")\n",
        "# model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
        "\n",
        "# Load the tools from the Toolbox server\n",
        "client = ToolboxClient(\"http://127.0.0.1:5000\")\n",
        "tools = client.load_toolset()\n",
        "\n",
        "# Create a Langraph agent\n",
        "agent = create_react_agent(model, tools, checkpointer=MemorySaver())\n",
        "config = {\"configurable\": {\"thread_id\": \"thread-1\"}}\n",
        "for query in queries:\n",
        "    #inputs = {\"messages\": [(\"user\", prompt + query)]}\n",
        "    response = agent.invoke(inputs, stream_mode=\"values\", config=config)\n",
        "    print(response[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from toolbox_langchain import ToolboxClient\n",
        "\n",
        "# The system prompt defining the agent's persona\n",
        "prompt = \"You are an Order Management Expert. You are good at querying on Order_number and extracting data from the table.\"\n",
        "\n",
        "queries = [\n",
        "    \"find the order_number details for order_number 1042567961\"\n",
        "]\n",
        "\n",
        "# --- LLM and Toolbox Setup ---\n",
        "BIGQUERY_PROJECT = \"genaipla-aiplayground2-sa-bf14\"\n",
        "\n",
        "# CORRECTED: Updated to a newer, more available model name.\n",
        "model = ChatVertexAI(\n",
        "    model_name=\"gemini-1.5-flash-preview-0514\",\n",
        "    project=BIGQUERY_PROJECT,\n",
        "    location=\"us-east1\"\n",
        ")\n",
        "\n",
        "# Load the tools from the Toolbox server\n",
        "client = ToolboxClient(\"http://127.0.0.1:5000\")\n",
        "tools = client.load_toolset()\n",
        "\n",
        "print(\"--- Tools Loaded ---\")\n",
        "print(tools)\n",
        "print(\"--------------------\")\n",
        "\n",
        "# Create a Langraph agent\n",
        "agent = create_react_agent(model, tools, checkpointer=MemorySaver())\n",
        "\n",
        "# --- Agent Invocation Loop ---\n",
        "config = {\"configurable\": {\"thread_id\": \"thread-1\"}}\n",
        "for query in queries:\n",
        "    print(f\"--- Processing Query: '{query}' ---\")\n",
        "\n",
        "    inputs = {\"messages\": [(\"system\", prompt), (\"user\", query)]}\n",
        "\n",
        "    # Using invoke to get the final answer directly\n",
        "    final_response = agent.invoke(inputs, config=config)\n",
        "\n",
        "    print(\"\\n--- Final Answer ---\")\n",
        "    print(final_response[\"messages\"][-1].content)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKq0bIFgWIQz",
        "outputId": "79be59f9-587e-4f37-e998-149d13d9845d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tools Loaded ---\n",
            "[ToolboxTool(name='search-order', description='Use this tool to get all details for a specific order by using its order number.\\n\\nArgs:\\n    order_number (str): The unique number for the order you need to find.', args_schema=<class 'toolbox_core.utils.search-order'>)]\n",
            "--------------------\n",
            "--- Processing Query: 'find the order_number details for order_number 1042567961' ---\n",
            "\n",
            "--- Final Answer ---\n",
            "I am sorry, I cannot fulfill your request. The available tools lack the functionality to provide the details of a specific order. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b6Loh8SJ_iA"
      },
      "outputs": [],
      "source": [
        "# Install the Toolbox LlamaIndex package\n",
        "!pip install toolbox-llamaindex --quiet\n",
        "\n",
        "# Install the llamaindex llm package\n",
        "# TODO(developer): replace this with another model if needed\n",
        "! pip install llama-index-llms-google-genai --quiet\n",
        "# ! pip install llama-index-llms-anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjsq_xXice11"
      },
      "source": [
        "Create a LlamaIndex Hotel Agent which can Search, Book and Cancel hotels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaBX4Dh6cU31"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import os\n",
        "\n",
        "from llama_index.core.agent.workflow import AgentWorkflow\n",
        "\n",
        "from llama_index.core.workflow import Context\n",
        "\n",
        "# TODO(developer): replace this with another import if needed\n",
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "# from llama_index.llms.anthropic import Anthropic\n",
        "\n",
        "from toolbox_llamaindex import ToolboxClient\n",
        "\n",
        "prompt = \"\"\"\n",
        "  You're a helpful hotel assistant. You handle hotel searching, booking and\n",
        "  cancellations. When the user searches for a hotel, mention it's name, id,\n",
        "  location and price tier. Always mention hotel ids while performing any\n",
        "  searches. This is very important for any operations. For any bookings or\n",
        "  cancellations, please provide the appropriate confirmation. Be sure to\n",
        "  update checkin or checkout dates if mentioned by the user.\n",
        "  Don't ask for confirmations from the user.\n",
        "\"\"\"\n",
        "\n",
        "queries = [\n",
        "    \"Find hotels in Basel with Basel in it's name.\",\n",
        "    \"Can you book the Hilton Basel for me?\",\n",
        "    \"Oh wait, this is too expensive. Please cancel it and book the Hyatt Regency instead.\",\n",
        "    \"My check in dates would be from April 10, 2024 to April 19, 2024.\",\n",
        "]\n",
        "\n",
        "async def run_agent():\n",
        "    # Create an LLM to bind with the agent.\n",
        "    # TODO(developer): replace this with another model if needed\n",
        "    llm = GoogleGenAI(\n",
        "        model=\"gemini-2.0-flash-001\",\n",
        "        vertexai_config={\"project\": BIGQUERY_PROJECT, \"location\": \"us-central1\"},\n",
        "    )\n",
        "    # llm = GoogleGenAI(\n",
        "    #     api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
        "    #     model=\"gemini-2.0-flash-001\",\n",
        "    # )\n",
        "    # llm = Anthropic(\n",
        "    #   model=\"claude-3-7-sonnet-latest\",\n",
        "    #   api_key=os.getenv(\"ANTHROPIC_API_KEY\")\n",
        "    # )\n",
        "\n",
        "    # Load the tools from the Toolbox server\n",
        "    client = ToolboxClient(\"http://127.0.0.1:5000\")\n",
        "    tools = client.load_toolset()\n",
        "\n",
        "    # Create a LlamaIndex agent\n",
        "    agent = AgentWorkflow.from_tools_or_functions(\n",
        "        tools,\n",
        "        llm=llm,\n",
        "        system_prompt=prompt,\n",
        "    )\n",
        "\n",
        "    # Run the agent\n",
        "    ctx = Context(agent)\n",
        "    for query in queries:\n",
        "        response = await agent.run(user_msg=query, ctx=ctx)\n",
        "        print(f\"---- {query} ----\")\n",
        "        print(str(response))\n",
        "\n",
        "await run_agent()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA3rAiELIds5"
      },
      "source": [
        "### Connect Using ADK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rphyouv2JtwX"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-adk\n",
        "!pip install -q toolbox-core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsc-bozAIXvo"
      },
      "outputs": [],
      "source": [
        "# Create an ADK Hotel Agent which can Search, Book and Cancel hotels.\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.artifacts.in_memory_artifact_service import InMemoryArtifactService\n",
        "from google.genai import types\n",
        "from toolbox_core import ToolboxSyncClient\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ['GOOGLE_GENAI_USE_VERTEXAI'] = 'True'\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = BIGQUERY_PROJECT\n",
        "os.environ['GOOGLE_CLOUD_LOCATION'] = 'us-central1'\n",
        "\n",
        "toolbox_client = ToolboxSyncClient(\"http://127.0.0.1:5000\")\n",
        "\n",
        "prompt = \"\"\"\n",
        "  You're a helpful hotel assistant. You handle hotel searching, booking and\n",
        "  cancellations. When the user searches for a hotel, mention it's name, id,\n",
        "  location and price tier. Always mention hotel ids while performing any\n",
        "  searches. This is very important for any operations. For any bookings or\n",
        "  cancellations, please provide the appropriate confirmation. Be sure to\n",
        "  update checkin or checkout dates if mentioned by the user.\n",
        "  Don't ask for confirmations from the user.\n",
        "\"\"\"\n",
        "\n",
        "root_agent = Agent(\n",
        "    model='gemini-2.0-flash-001',\n",
        "    name='hotel_agent',\n",
        "    description='A helpful AI assistant.',\n",
        "    instruction=prompt,\n",
        "    tools=toolbox_client.load_toolset(\"my-toolset\"),\n",
        ")\n",
        "\n",
        "session_service = InMemorySessionService()\n",
        "artifacts_service = InMemoryArtifactService()\n",
        "session = session_service.create_session(\n",
        "    state={}, app_name='hotel_agent', user_id='123'\n",
        ")\n",
        "runner = Runner(\n",
        "    app_name='hotel_agent',\n",
        "    agent=root_agent,\n",
        "    artifact_service=artifacts_service,\n",
        "    session_service=session_service,\n",
        ")\n",
        "\n",
        "queries = [\n",
        "    \"Find hotels in Basel with Basel in it's name.\",\n",
        "    \"Can you book the Hilton Basel for me?\",\n",
        "    \"Oh wait, this is too expensive. Please cancel it and book the Hyatt Regency instead.\",\n",
        "    \"My check in dates would be from April 10, 2024 to April 19, 2024.\",\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    content = types.Content(role='user', parts=[types.Part(text=query)])\n",
        "    events = runner.run(session_id=session.id,\n",
        "                        user_id='123', new_message=content)\n",
        "\n",
        "    responses = (\n",
        "      part.text\n",
        "      for event in events\n",
        "      for part in event.content.parts\n",
        "      if part.text is not None\n",
        "    )\n",
        "\n",
        "    for text in responses:\n",
        "      print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd-wF_Z9vVe3"
      },
      "source": [
        "### Observe the output\n",
        "\n",
        "You can see that the `Hyatt Regency Basel` has been booked for the correct dates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTW9bTUoqHis"
      },
      "outputs": [],
      "source": [
        "sql_select = f\"SELECT * FROM `{BIGQUERY_PROJECT}.{DATASET}.{TABLE_ID}`\"\n",
        "query_job = bqclient.query(sql_select)\n",
        "\n",
        "print(\"\\nQuery results:\")\n",
        "query_job.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCRH0542KC51"
      },
      "source": [
        "### Clean-Up\n",
        "Conditionally delete BigQuery table and dataset in final session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8W1N0rpz5Iq"
      },
      "outputs": [],
      "source": [
        "bqclient.delete_table(table_ref, not_found_ok=True)\n",
        "\n",
        "bqclient.get_dataset(dataset_ref)\n",
        "tables_in_dataset = list(bqclient.list_tables(dataset_ref))\n",
        "if not tables_in_dataset:\n",
        "    bqclient.delete_dataset(dataset_ref, delete_contents=False, not_found_ok=True)\n",
        "    print(f\"Dataset '{DATASET}' deleted.\")\n",
        "else:\n",
        "    print(f\"Dataset '{DATASET}' is not empty. Skipping dataset deletion.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}